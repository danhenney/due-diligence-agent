"""Streamlit web UI for the Due Diligence Agent."""
import json
import os
import shutil
import tempfile
import threading
import time
import uuid
from datetime import datetime
from pathlib import Path

REPORTS_DIR = Path("reports")
_JOBS_DIR = REPORTS_DIR / "jobs"

# Max concurrent analyses. Additional submissions wait in queue.
_ANALYSIS_SEMAPHORE = threading.Semaphore(2)

# Jobs stuck in "running" longer than this are marked as timed-out.
_STALE_JOB_TIMEOUT_SEC = 5400  # 90 minutes


# â”€â”€ File-based job state (survives multi-process + navigation) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _job_file(job_id: str) -> Path:
    _JOBS_DIR.mkdir(parents=True, exist_ok=True)
    return _JOBS_DIR / f"{job_id}.json"


def _read_job(job_id: str) -> dict:
    f = _job_file(job_id)
    try:
        if f.exists():
            data = json.loads(f.read_text(encoding="utf-8"))
            # Auto-expire stale "running" jobs (e.g. after a server restart mid-run)
            if data.get("status") in ("running", "queued"):
                start = data.get("start_time") or 0
                if start and time.time() - start > _STALE_JOB_TIMEOUT_SEC:
                    data["status"] = "error"
                    data["error"] = (
                        "Analysis timed out or the server was restarted mid-run. "
                        "Please submit again."
                    )
            return data
    except Exception:
        pass
    return {"status": "unknown", "progress": [], "error": None, "start_time": None}


def _update_job(job_id: str, updates: dict) -> None:
    """Merge updates into the job file using an atomic tmpâ†’rename write."""
    f = _job_file(job_id)
    data = _read_job(job_id)
    data.update(updates)
    tmp = f.with_suffix(".tmp")
    tmp.write_text(json.dumps(data, ensure_ascii=False), encoding="utf-8")
    tmp.replace(f)


# â”€â”€ History â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _load_history() -> list[dict]:
    hist_file = REPORTS_DIR / "history.json"
    if hist_file.exists():
        try:
            return json.loads(hist_file.read_text(encoding="utf-8"))
        except Exception:
            return []
    return []


def _save_history_entry(entry: dict) -> None:
    hist_file = REPORTS_DIR / "history.json"
    history = _load_history()
    history.insert(0, entry)
    REPORTS_DIR.mkdir(exist_ok=True)
    hist_file.write_text(json.dumps(history, indent=2, ensure_ascii=False), encoding="utf-8")


# â”€â”€ Token cost tracking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# claude-sonnet-4-6 pricing (USD per 1M tokens)
_PRICE_INPUT_PER_M  = 3.00
_PRICE_OUTPUT_PER_M = 15.00

# Human-readable labels for each agent key
_AGENT_LABELS_EN = {
    "financial_analyst": "Financial Analyst",
    "market_research":   "Market Research",
    "legal_risk":        "Legal Risk",
    "management_team":   "Management Team",
    "tech_product":      "Tech & Product",
    "bull_case":         "Bull Case",
    "bear_case":         "Bear Case",
    "valuation":         "Valuation",
    "red_flag":          "Red Flag Hunter",
    "fact_checker":      "Fact Checker",
    "stress_test":       "Stress Test",
    "completeness":      "Completeness",
    "final_report_agent":"Final Report",
}

_AGENT_LABELS_KO = {
    "financial_analyst": "ì¬ë¬´ ë¶„ì„ê°€",
    "market_research":   "ì‹œì¥ ë¦¬ì„œì²˜",
    "legal_risk":        "ë²•ì  ë¦¬ìŠ¤í¬ ë¶„ì„ê°€",
    "management_team":   "ê²½ì˜ì§„ ë¶„ì„ê°€",
    "tech_product":      "ê¸°ìˆ Â·ì œí’ˆ ë¶„ì„ê°€",
    "bull_case":         "ê°•ì„¸ ë…¼ê±° ë¶„ì„ê°€",
    "bear_case":         "ì•½ì„¸ ë…¼ê±° ë¶„ì„ê°€",
    "valuation":         "ë°¸ë¥˜ì—ì´ì…˜ ë¶„ì„ê°€",
    "red_flag":          "ìœ„í—˜ ì‹ í˜¸ íƒì§€ê¸°",
    "fact_checker":      "íŒ©íŠ¸ì²´ì»¤",
    "stress_test":       "ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ë¶„ì„ê°€",
    "completeness":      "ì™„ì„±ë„ ê²€ì‚¬ê¸°",
    "final_report_agent":"ìµœì¢… ë³´ê³ ì„œ ì—ì´ì „íŠ¸",
}

# Display order
_AGENT_ORDER = list(_AGENT_LABELS_EN.keys())


def _cost_usd(inp: int, out: int) -> float:
    return inp / 1_000_000 * _PRICE_INPUT_PER_M + out / 1_000_000 * _PRICE_OUTPUT_PER_M


# â”€â”€ Background worker â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _analysis_worker(job_id: str, initial_state: dict, company: str, tmp_dir: str) -> None:
    """Daemon thread â€” waits for a semaphore slot, then runs the full pipeline."""
    # Wait for a free slot (max 2 concurrent analyses)
    _update_job(job_id, {"status": "queued"})
    _ANALYSIS_SEMAPHORE.acquire()
    try:
        _update_job(job_id, {"status": "running", "start_time": time.time()})
        _run_pipeline(job_id, initial_state, company, tmp_dir)
    finally:
        _ANALYSIS_SEMAPHORE.release()


def _run_pipeline(job_id: str, initial_state: dict, company: str, tmp_dir: str) -> None:
    """Inner worker â€” runs all pipeline nodes and writes results to disk."""
    try:
        import pdf_report
        from agents.base import get_and_reset_usage
        from graph.workflow import (
            input_processor, phase1_parallel, phase1_aggregator,
            phase2_parallel, phase2_aggregator,
            fact_checker_node, stress_test_node,
            completeness_node, final_report_node,
        )

        state: dict = dict(initial_state)
        progress: list[str] = []
        token_usage: dict = {}   # agent_key -> {input_tokens, output_tokens, cost_usd}

        # Nodes that don't call the LLM (no cost to track)
        _NO_LLM_NODES = {"input_processor", "phase1_aggregator", "phase2_aggregator"}

        def _step(fn, node_name: str) -> None:
            result = fn(state)
            state.update(result)
            progress.append(node_name)

            if node_name in ("phase1_parallel", "phase2_parallel"):
                # Per-sub-agent usage is captured inside workflow.py and
                # returned in state["__agent_usage__"]
                for agent_key, usage in (state.pop("__agent_usage__", {}) or {}).items():
                    token_usage[agent_key] = {
                        "input_tokens":  usage["input_tokens"],
                        "output_tokens": usage["output_tokens"],
                        "cost_usd":      _cost_usd(usage["input_tokens"], usage["output_tokens"]),
                    }
            elif node_name not in _NO_LLM_NODES:
                # Sequential agent â€” usage is on this thread
                usage = get_and_reset_usage()
                # node_name for phase3/4 agents matches the agent key
                agent_key = node_name
                token_usage[agent_key] = {
                    "input_tokens":  usage["input_tokens"],
                    "output_tokens": usage["output_tokens"],
                    "cost_usd":      _cost_usd(usage["input_tokens"], usage["output_tokens"]),
                }

            _update_job(job_id, {
                "progress":    progress.copy(),
                "token_usage": token_usage.copy(),
            })

        _step(input_processor,   "input_processor")
        _step(phase1_parallel,   "phase1_parallel")
        _step(phase1_aggregator, "phase1_aggregator")
        _step(phase2_parallel,   "phase2_parallel")
        _step(phase2_aggregator, "phase2_aggregator")
        _step(fact_checker_node, "fact_checker")
        _step(stress_test_node,  "stress_test")
        _step(completeness_node, "completeness")
        _step(final_report_node, "final_report_agent")

        pdf_path = pdf_report.generate_pdf(state, job_id)

        _save_history_entry({
            "id": job_id,
            "company": company,
            "recommendation": (state.get("recommendation") or "WATCH").upper(),
            "date": datetime.now().strftime("%Y-%m-%d %H:%M"),
            "pdf_path": str(pdf_path),
        })

        _update_job(job_id, {
            "status":         "complete",
            "pdf_path":       str(pdf_path),
            "recommendation": (state.get("recommendation") or "WATCH").upper(),
            "final_report":   state.get("final_report") or "",
            "token_usage":    token_usage,
        })

    except Exception as exc:
        _update_job(job_id, {"status": "error", "error": str(exc)})

    finally:
        shutil.rmtree(tmp_dir, ignore_errors=True)

import streamlit as st

# Inject Streamlit Cloud secrets into os.environ so config.py's os.getenv() works.
# This is a no-op when running locally with a .env file.
try:
    for _k in ["ANTHROPIC_API_KEY", "TAVILY_API_KEY", "EDGAR_USER_AGENT"]:
        if _k in st.secrets and not os.environ.get(_k):
            os.environ[_k] = str(st.secrets[_k])
except Exception:
    pass

from config import validate_config

# â”€â”€ UI Translations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_UI = {
    "en": {
        "app_title":            "## ğŸ“Š Due Diligence Agent",
        "app_subtitle":         "Submit a company â†’ 13 AI agents analyze it in 4 phases â†’ full investment memo + PDF",
        "history_btn":          "ğŸ• History",
        "form_heading":         "#### Submit a Company",
        "company_label":        "Company Name",
        "company_placeholder":  "e.g. Apple, OpenAI, Stripe",
        "url_label":            "Website URL *(required â€” improves research quality)*",
        "url_placeholder":      "https://example.com",
        "report_lang_label":    "Report Language",
        "docs_label":           "Supporting Documents *(optional)*",
        "docs_help":            "Pitch decks, 10-Ks, annual reports, etc.",
        "cost_caption":         "Typical cost: **$1 â€“ $5 per analysis** Â· 13 agents Â· claude-sonnet-4-6 Â· $3/M input Â· $15/M output",
        "run_btn":              "ğŸ”  Run Due Diligence",
        "pipeline_heading":     "#### Agent Pipeline Flow",
        "pipeline_caption":     "Phases 1 & 2 run agents in parallel. Phase 3 is sequential (order matters).",
        "directory_heading":    "#### Agent Directory",
        "directory_caption":    "Click any agent to see its methodology and data sources.",
        "how_it_works":         "**How it works:**",
        "sources_label":        "**Sources:**",
        "methodology_expander": "Methodology & Sources",
        "analyzing":            "## ğŸ“Š Analyzing {}â€¦",
        "running_caption":      "Running in the background â€” you can navigate away and come back at any time.",
        "api_cost":             "**API cost so far: ${cost:.4f}**  Â·  {inp:,} input tokens  Â·  {out:,} output tokens  Â·  Pricing: $3/M input Â· $15/M output (claude-sonnet-4-6)",
        "queued_heading":       "## ğŸ“Š {} â€” Queued",
        "queued_caption":       "Two analyses are already running. Yours will start automatically when a slot opens.",
        "queued_info":          "**Your analysis is in the queue.**\n\nThe server allows 2 simultaneous analyses to avoid API rate limits. You're next in line â€” this page will update automatically when it starts.",
        "waiting_caption":      "Waitingâ€¦ {}s in queue",
        "analysis_failed":      "**Analysis failed:** {}",
        "try_again_btn":        "â† Try Again",
        "invest_desc":          "Strong investment opportunity with compelling fundamentals.",
        "watch_desc":           "Interesting opportunity â€” monitor for further developments.",
        "pass_desc":            "Risks outweigh opportunities at this time.",
        "download_btn":         "â¬‡ï¸  Download PDF Report",
        "analyze_another_btn":  "ğŸ”„  Analyze Another Company",
        "token_expander":       "Token Usage & Cost  â€”  **${:.4f} total**",
        "token_caption":        "Pricing: claude-sonnet-4-6 Â· $3.00 / 1M input tokens Â· $15.00 / 1M output tokens",
        "no_report":            "No report content was generated.",
        "agent_col":            "Agent",
        "input_tokens_col":     "Input tokens",
        "output_tokens_col":    "Output tokens",
        "cost_col":             "Cost (USD)",
        "total_label":          "**TOTAL**",
        "history_title":        "## ğŸ• Analysis History",
        "history_caption":      "All due diligence reports generated on this machine.",
        "back_btn":             "â† Back",
        "back_running_btn":     "â† Back to Running Analysis",
        "no_history":           "No analyses yet. Submit a company on the main page to get started.",
        "pdf_btn":              "â¬‡ï¸ PDF",
        "pdf_unavail":          "PDF unavailable",
        "password_label":       "Password",
        "password_placeholder": "Enter password to continue",
        "unlock_btn":           "Unlock",
        "wrong_password":       "Incorrect password.",
        "lang_toggle":          "í•œêµ­ì–´",
        "step_done":            "âœ“",
        "step_running":         "â³",
        "progress_text":        "**{pct}%** â€” step {done} of {total}  Â·  elapsed {elapsed}  Â·  {eta}",
        "eta_estimating":       "Estimatingâ€¦",
        "eta_remaining":        "~{} remaining",
    },
    "ko": {
        "app_title":            "## ğŸ“Š ì‹¤ì‚¬ ì—ì´ì „íŠ¸",
        "app_subtitle":         "ê¸°ì—…ì„ ì…ë ¥í•˜ë©´ â†’ AI ì—ì´ì „íŠ¸ 13ê°œê°€ 4ë‹¨ê³„ë¡œ ë¶„ì„ â†’ íˆ¬ì ë©”ëª¨ + PDF ì™„ì„±",
        "history_btn":          "ğŸ• ë¶„ì„ ê¸°ë¡",
        "form_heading":         "#### ê¸°ì—… ë¶„ì„ ìš”ì²­",
        "company_label":        "ê¸°ì—…ëª…",
        "company_placeholder":  "ì˜ˆ: Apple, OpenAI, ì¹´ì¹´ì˜¤",
        "url_label":            "ê³µì‹ ì›¹ì‚¬ì´íŠ¸ *(í•„ìˆ˜ â€” ë¶„ì„ í’ˆì§ˆ í–¥ìƒ)*",
        "url_placeholder":      "https://example.com",
        "report_lang_label":    "ë³´ê³ ì„œ ì–¸ì–´",
        "docs_label":           "ì°¸ê³  ë¬¸ì„œ *(ì„ íƒ)*",
        "docs_help":            "ì‚¬ì—…ê³„íšì„œ, 10-K, ì—°ê°„ë³´ê³ ì„œ ë“± PDF",
        "cost_caption":         "ì˜ˆìƒ ë¹„ìš©: **ë¶„ì„ë‹¹ $1 â€“ $5** Â· ì—ì´ì „íŠ¸ 13ê°œ Â· claude-sonnet-4-6 Â· ì…ë ¥ $3/M Â· ì¶œë ¥ $15/M",
        "run_btn":              "ğŸ”  ì‹¤ì‚¬ ë¶„ì„ ì‹œì‘",
        "pipeline_heading":     "#### ì—ì´ì „íŠ¸ íŒŒì´í”„ë¼ì¸",
        "pipeline_caption":     "1Â·2ë‹¨ê³„ëŠ” ì—ì´ì „íŠ¸ë¥¼ ë³‘ë ¬ ì‹¤í–‰í•©ë‹ˆë‹¤. 3ë‹¨ê³„ëŠ” ìˆœì°¨ ì‹¤í–‰ì…ë‹ˆë‹¤.",
        "directory_heading":    "#### ì—ì´ì „íŠ¸ ëª©ë¡",
        "directory_caption":    "ì—ì´ì „íŠ¸ë¥¼ í´ë¦­í•˜ë©´ ë¶„ì„ ë°©ë²•ë¡ ê³¼ ë°ì´í„° ì†ŒìŠ¤ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "how_it_works":         "**ë¶„ì„ ë°©ë²•:**",
        "sources_label":        "**ë°ì´í„° ì†ŒìŠ¤:**",
        "methodology_expander": "ë°©ë²•ë¡  & ì†ŒìŠ¤",
        "analyzing":            "## ğŸ“Š {} ë¶„ì„ ì¤‘â€¦",
        "running_caption":      "ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ ì¤‘ â€” í˜ì´ì§€ë¥¼ ë²—ì–´ë‚¬ë‹¤ê°€ ì–¸ì œë“  ëŒì•„ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "api_cost":             "**í˜„ì¬ API ë¹„ìš©: ${cost:.4f}**  Â·  ì…ë ¥ í† í° {inp:,}ê°œ  Â·  ì¶œë ¥ í† í° {out:,}ê°œ  Â·  ê°€ê²©: ì…ë ¥ $3/M Â· ì¶œë ¥ $15/M",
        "queued_heading":       "## ğŸ“Š {} â€” ëŒ€ê¸° ì¤‘",
        "queued_caption":       "í˜„ì¬ 2ê°œì˜ ë¶„ì„ì´ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. ìŠ¬ë¡¯ì´ ì—´ë¦¬ë©´ ìë™ìœ¼ë¡œ ì‹œì‘ë©ë‹ˆë‹¤.",
        "queued_info":          "**ë¶„ì„ì´ ëŒ€ê¸°ì—´ì— ìˆìŠµë‹ˆë‹¤.**\n\nAPI ì†ë„ ì œí•œì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì„œë²„ëŠ” ìµœëŒ€ 2ê°œì˜ ë™ì‹œ ë¶„ì„ì„ í—ˆìš©í•©ë‹ˆë‹¤. ë‹¤ìŒ ìˆœì„œì…ë‹ˆë‹¤ â€” ì‹œì‘ë˜ë©´ ì´ í˜ì´ì§€ê°€ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.",
        "waiting_caption":      "ëŒ€ê¸° ì¤‘â€¦ {}ì´ˆ ê²½ê³¼",
        "analysis_failed":      "**ë¶„ì„ ì‹¤íŒ¨:** {}",
        "try_again_btn":        "â† ë‹¤ì‹œ ì‹œë„",
        "invest_desc":          "ê°•ë ¥í•œ íˆ¬ì ê¸°íšŒ â€” íƒ„íƒ„í•œ í€ë”ë©˜í„¸ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
        "watch_desc":           "í¥ë¯¸ë¡œìš´ ê¸°íšŒ â€” ì¶”ê°€ ë™í–¥ì„ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”.",
        "pass_desc":            "í˜„ì¬ ì‹œì ì—ì„œ ë¦¬ìŠ¤í¬ê°€ ê¸°íšŒë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.",
        "download_btn":         "â¬‡ï¸  PDF ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
        "analyze_another_btn":  "ğŸ”„  ë‹¤ë¥¸ ê¸°ì—… ë¶„ì„",
        "token_expander":       "í† í° ì‚¬ìš©ëŸ‰ & ë¹„ìš©  â€”  **ì´ ${:.4f}**",
        "token_caption":        "ê°€ê²©: claude-sonnet-4-6 Â· ì…ë ¥ $3.00 / 1M í† í° Â· ì¶œë ¥ $15.00 / 1M í† í°",
        "no_report":            "ìƒì„±ëœ ë³´ê³ ì„œ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.",
        "agent_col":            "ì—ì´ì „íŠ¸",
        "input_tokens_col":     "ì…ë ¥ í† í°",
        "output_tokens_col":    "ì¶œë ¥ í† í°",
        "cost_col":             "ë¹„ìš© (USD)",
        "total_label":          "**í•©ê³„**",
        "history_title":        "## ğŸ• ë¶„ì„ ê¸°ë¡",
        "history_caption":      "ì´ ì„œë²„ì—ì„œ ìƒì„±ëœ ëª¨ë“  ì‹¤ì‚¬ ë³´ê³ ì„œ",
        "back_btn":             "â† ë’¤ë¡œ",
        "back_running_btn":     "â† ì§„í–‰ ì¤‘ì¸ ë¶„ì„ìœ¼ë¡œ ëŒì•„ê°€ê¸°",
        "no_history":           "ì•„ì§ ë¶„ì„ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤. ë©”ì¸ í˜ì´ì§€ì—ì„œ ê¸°ì—…ì„ ì…ë ¥í•˜ì—¬ ì‹œì‘í•˜ì„¸ìš”.",
        "pdf_btn":              "â¬‡ï¸ PDF",
        "pdf_unavail":          "PDF ì—†ìŒ",
        "password_label":       "ë¹„ë°€ë²ˆí˜¸",
        "password_placeholder": "ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
        "unlock_btn":           "ì ê¸ˆ í•´ì œ",
        "wrong_password":       "ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.",
        "lang_toggle":          "English",
        "step_done":            "âœ“",
        "step_running":         "â³",
        "progress_text":        "**{pct}%** â€” {done}/{total}ë‹¨ê³„  Â·  ê²½ê³¼ {elapsed}  Â·  {eta}",
        "eta_estimating":       "ì˜ˆìƒ ì¤‘â€¦",
        "eta_remaining":        "~{} ë‚¨ìŒ",
    },
}


def t(key: str, *args, **kwargs) -> str:
    """Return translated UI string for the current ui_lang session."""
    lang = st.session_state.get("ui_lang", "en")
    s = _UI.get(lang, _UI["en"]).get(key) or _UI["en"].get(key, key)
    if args:
        return s.format(*args)
    if kwargs:
        return s.format(**kwargs)
    return s


# â”€â”€ Node labels (language-aware at render time) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_NODE_LABELS_EN = {
    "input_processor":    "ğŸ” Processing inputs",
    "phase1_parallel":    "ğŸ“Š Phase 1 â€” 5 research agents ran in parallel",
    "phase1_aggregator":  "âœ… Phase 1 aggregated",
    "phase2_parallel":    "ğŸ“ˆ Phase 2 â€” 4 analysis agents ran in parallel",
    "phase2_aggregator":  "âœ… Phase 2 aggregated",
    "fact_checker":       "ğŸ” Fact-checking all claims",
    "stress_test":        "âš¡ Stress-testing downside scenarios",
    "completeness":       "ğŸ“‹ Coverage & completeness review",
    "final_report_agent": "ğŸ“ Writing investment memo",
}

_NODE_LABELS_KO = {
    "input_processor":    "ğŸ” ì…ë ¥ ì²˜ë¦¬ ì¤‘",
    "phase1_parallel":    "ğŸ“Š 1ë‹¨ê³„ â€” ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ 5ê°œ ë³‘ë ¬ ì‹¤í–‰",
    "phase1_aggregator":  "âœ… 1ë‹¨ê³„ ì§‘ê³„ ì™„ë£Œ",
    "phase2_parallel":    "ğŸ“ˆ 2ë‹¨ê³„ â€” ë¶„ì„ ì—ì´ì „íŠ¸ 4ê°œ ë³‘ë ¬ ì‹¤í–‰",
    "phase2_aggregator":  "âœ… 2ë‹¨ê³„ ì§‘ê³„ ì™„ë£Œ",
    "fact_checker":       "ğŸ” ëª¨ë“  ì£¼ì¥ íŒ©íŠ¸ì²´í¬",
    "stress_test":        "âš¡ í•˜ë°© ì‹œë‚˜ë¦¬ì˜¤ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸",
    "completeness":       "ğŸ“‹ ì»¤ë²„ë¦¬ì§€ & ì™„ì„±ë„ ê²€í† ",
    "final_report_agent": "ğŸ“ íˆ¬ì ë©”ëª¨ ì‘ì„± ì¤‘",
}

# Weighted % of total runtime each node typically consumes (must sum to 100)
NODE_WEIGHTS = {
    "input_processor":    2,
    "phase1_parallel":    35,
    "phase1_aggregator":  1,
    "phase2_parallel":    28,
    "phase2_aggregator":  1,
    "fact_checker":       12,
    "stress_test":        9,
    "completeness":       6,
    "final_report_agent": 6,
}

# â”€â”€ Pipeline graphviz diagram â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PIPELINE_GRAPH = """
digraph pipeline {
    rankdir=LR;
    node [fontname="Helvetica" fontsize=9 style="rounded,filled" shape=box margin=0.15];
    edge [arrowsize=0.6 color="#94a3b8"];

    START [label="START" shape=circle fillcolor="#6366f1" fontcolor=white
           style=filled width=0.45 height=0.45 fontsize=8];
    END   [label="END"   shape=circle fillcolor="#059669" fontcolor=white
           style=filled width=0.45 height=0.45 fontsize=8];

    inp [label="Input\nProcessor" fillcolor="#e0e7ff" color="#6366f1" fontcolor="#3730a3"];

    subgraph cluster_p1 {
        label="Phase 1  âŸµ  Parallel" fontsize=9 color="#2563eb"
        fillcolor="#eff6ff" style="rounded,filled";
        fin  [label="Financial\nAnalyst"  fillcolor="#bfdbfe" color="#1d4ed8" fontcolor="#1e3a8a"];
        mkt  [label="Market\nResearch"   fillcolor="#bfdbfe" color="#1d4ed8" fontcolor="#1e3a8a"];
        leg  [label="Legal Risk"         fillcolor="#bfdbfe" color="#1d4ed8" fontcolor="#1e3a8a"];
        mgmt [label="Management\nTeam"   fillcolor="#bfdbfe" color="#1d4ed8" fontcolor="#1e3a8a"];
        tech [label="Tech &\nProduct"    fillcolor="#bfdbfe" color="#1d4ed8" fontcolor="#1e3a8a"];
    }

    agg1 [label="â¬‡" shape=diamond fillcolor="#dbeafe" color="#2563eb"
          width=0.3 height=0.3 fontsize=11];

    subgraph cluster_p2 {
        label="Phase 2  âŸµ  Parallel" fontsize=9 color="#7c3aed"
        fillcolor="#f5f3ff" style="rounded,filled";
        bull [label="Bull Case"  fillcolor="#ddd6fe" color="#7c3aed" fontcolor="#4c1d95"];
        bear [label="Bear Case"  fillcolor="#ddd6fe" color="#7c3aed" fontcolor="#4c1d95"];
        val  [label="Valuation"  fillcolor="#ddd6fe" color="#7c3aed" fontcolor="#4c1d95"];
        red  [label="Red Flags"  fillcolor="#ddd6fe" color="#7c3aed" fontcolor="#4c1d95"];
    }

    agg2 [label="â¬‡" shape=diamond fillcolor="#ede9fe" color="#7c3aed"
          width=0.3 height=0.3 fontsize=11];

    subgraph cluster_p3 {
        label="Phase 3  âŸµ  Sequential" fontsize=9 color="#d97706"
        fillcolor="#fffbeb" style="rounded,filled";
        fact   [label="Fact\nChecker"  fillcolor="#fde68a" color="#b45309" fontcolor="#78350f"];
        stress [label="Stress\nTest"   fillcolor="#fde68a" color="#b45309" fontcolor="#78350f"];
        comp   [label="Complete-\nness" fillcolor="#fde68a" color="#b45309" fontcolor="#78350f"];
    }

    final [label="Final\nReport" fillcolor="#d1fae5" color="#059669" fontcolor="#064e3b"];

    START -> inp;
    inp -> fin; inp -> mkt; inp -> leg; inp -> mgmt; inp -> tech;
    fin -> agg1; mkt -> agg1; leg -> agg1; mgmt -> agg1; tech -> agg1;
    agg1 -> bull; agg1 -> bear; agg1 -> val; agg1 -> red;
    bull -> agg2; bear -> agg2; val -> agg2; red -> agg2;
    agg2 -> fact;
    fact -> stress [label="  then  " fontsize=7 color="#d97706"];
    stress -> comp [label="  then  " fontsize=7 color="#d97706"];
    comp -> final;
    final -> END;
}
"""

# â”€â”€ Agent directory data (English) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
AGENT_PHASES = [
    {
        "label": "Phase 1 â€” Parallel Research",
        "color": "#1d4ed8",
        "bg": "#eff6ff",
        "description": "5 specialist agents run **simultaneously**. Each independently researches a different dimension of the company. None waits for the others.",
        "agents": [
            {
                "icon": "ğŸ’°",
                "name": "Financial Analyst",
                "role": "Assesses financial health, profitability, and accounting quality.",
                "methodology": [
                    "Pulls SEC 10-K / 10-Q filings from EDGAR",
                    "Calculates key ratios: gross margin, EBITDA margin, D/E ratio, current ratio",
                    "Trends revenue, operating income, free cash flow year-over-year",
                    "Checks for revenue concentration risk and accounting red flags",
                    "Compares metrics against industry benchmarks",
                ],
                "sources": ["SEC EDGAR (10-K, 10-Q, 8-K)", "Yahoo Finance (yfinance)", "Web search", "Uploaded PDFs"],
            },
            {
                "icon": "ğŸŒ",
                "name": "Market Research",
                "role": "Estimates TAM/SAM, maps the competitive landscape, and identifies macro trends.",
                "methodology": [
                    "Estimates Total Addressable Market (TAM) and Serviceable Market (SAM)",
                    "Maps direct competitors, indirect substitutes, and market share",
                    "Identifies macro tailwinds/headwinds (regulation, demographics, tech shifts)",
                    "Evaluates company positioning and differentiation vs. rivals",
                    "Assesses barriers to entry and market defensibility",
                ],
                "sources": ["Web search", "News search", "Google Trends (pytrends)", "FRED macroeconomic data", "Industry reports"],
            },
            {
                "icon": "âš–ï¸",
                "name": "Legal Risk Analyst",
                "role": "Surfaces litigation, regulatory exposure, IP risks, and governance issues.",
                "methodology": [
                    "Searches for active lawsuits, class actions, and settlements",
                    "Reviews regulatory compliance status and recent enforcement actions",
                    "Assesses IP portfolio strength and patent disputes",
                    "Evaluates data privacy posture (GDPR, CCPA) and ESG exposure",
                    "Flags corporate governance red flags and insider conflicts",
                ],
                "sources": ["Web search", "News search", "USPTO PatentsView (patent database)", "Uploaded PDFs (legal docs)"],
            },
            {
                "icon": "ğŸ‘¥",
                "name": "Management Team Analyst",
                "role": "Evaluates founders, executives, board, and organizational maturity.",
                "methodology": [
                    "Reviews founder/CEO background, domain expertise, and track record",
                    "Assesses executive team completeness and prior startup experience",
                    "Evaluates board composition (independence, relevant expertise)",
                    "Identifies key-person dependency and succession risks",
                    "Surfaces culture signals and employee sentiment (Glassdoor, press)",
                ],
                "sources": ["Web search", "News search", "LinkedIn (via web)"],
            },
            {
                "icon": "ğŸ”¬",
                "name": "Tech & Product Analyst",
                "role": "Evaluates product maturity, technical moat, scalability, and PMF.",
                "methodology": [
                    "Assesses product stage (MVP / growth / mature) and feature depth",
                    "Evaluates technical differentiation and defensibility (IP, data moats)",
                    "Reviews scalability architecture and infrastructure choices",
                    "Measures product-market fit signals (NPS, churn, retention)",
                    "Benchmarks engineering team size and development velocity",
                ],
                "sources": ["Web search", "News search", "GitHub API (repos, commit activity, contributors)", "Google Trends (pytrends)", "USPTO PatentsView"],
            },
        ],
    },
    {
        "label": "Phase 2 â€” Parallel Analysis",
        "color": "#7c3aed",
        "bg": "#f5f3ff",
        "description": "4 thesis agents run **simultaneously**, each reading all Phase 1 reports. They argue different angles to stress-test the opportunity from every direction.",
        "agents": [
            {
                "icon": "ğŸ“ˆ",
                "name": "Bull Case Analyst",
                "role": "Builds the strongest possible investment thesis and quantifies upside.",
                "methodology": [
                    "Synthesizes Phase 1 findings to construct the best-case scenario",
                    "Identifies top catalysts (product launches, market expansion, M&A)",
                    "Assigns probability weights and timelines to each catalyst",
                    "Projects revenue trajectory and valuation upside in bull scenario",
                    "Articulates competitive advantages and why the company can win",
                ],
                "sources": ["Phase 1 reports (financial, market, legal, management, tech)"],
            },
            {
                "icon": "ğŸ“‰",
                "name": "Bear Case Analyst",
                "role": "Constructs the strongest argument against investing and identifies fatal flaws.",
                "methodology": [
                    "Stress-tests Phase 1 findings for weaknesses and inconsistencies",
                    "Assigns realistic likelihood and severity scores to each risk",
                    "Models worst-case scenario with quantified revenue/valuation impact",
                    "Identifies structural weaknesses that competitors could exploit",
                    "Flags management and financial concerns that may be deal-breakers",
                ],
                "sources": ["Phase 1 reports (financial, market, legal, management, tech)"],
            },
            {
                "icon": "ğŸ§®",
                "name": "Valuation Analyst",
                "role": "Estimates fair value using DCF, revenue multiples, and precedent transactions.",
                "methodology": [
                    "Runs revenue/EBITDA multiple analysis vs. comparable public companies",
                    "Builds DCF model with bull/base/bear assumptions",
                    "Reviews precedent M&A transactions in the sector",
                    "Produces a fair value range (low / mid / high) with confidence intervals",
                    "Calculates implied upside/downside to current valuation",
                ],
                "sources": ["Yahoo Finance (yfinance â€” live multiples, analyst targets)", "Web search", "Phase 1 financial & market reports"],
            },
            {
                "icon": "ğŸš©",
                "name": "Red Flag Hunter",
                "role": "Cross-examines all Phase 1 reports for contradictions, omissions, and fraud signals.",
                "methodology": [
                    "Compares claims across all 5 Phase 1 reports for inconsistencies",
                    "Detects classic fraud signals: revenue â‰  cash flow, customer concentration",
                    "Identifies suspicious omissions and missing critical information",
                    "Flags related-party transactions and unusual accounting treatments",
                    "Rates each flag by severity (high / medium / low) with evidence",
                ],
                "sources": ["Phase 1 reports (cross-referenced against each other)"],
            },
        ],
    },
    {
        "label": "Phase 3 â€” Sequential Verification",
        "color": "#b45309",
        "bg": "#fffbeb",
        "description": "3 QA agents run **one after another** â€” each depends on the previous one's output. Order matters: verify facts first, then stress-test, then check for gaps.",
        "agents": [
            {
                "icon": "ğŸ”",
                "name": "Fact Checker",
                "role": "Independently verifies every material claim made in Phases 1 & 2.",
                "methodology": [
                    "Extracts all material factual claims from Phase 1 & 2 reports",
                    "Independently searches for primary sources to confirm or refute each claim",
                    "Classifies each as: VERIFIED / UNVERIFIED / CONTRADICTED / MISSING",
                    "Assigns a confidence score and cites the verification source",
                    "Outputs overall factual integrity score for the entire DD package",
                ],
                "sources": ["Web search", "News search", "Phase 1 & 2 reports"],
            },
            {
                "icon": "âš¡",
                "name": "Stress Test Analyst",
                "role": "Models three downside scenarios with quantified financial impact.",
                "methodology": [
                    "**Base Stress**: Moderate deterioration (mild recession, execution miss)",
                    "**Severe Stress**: Major adverse event (big competitor, regulatory action)",
                    "**Catastrophic**: Existential risk (fraud, bankruptcy, tech disruption)",
                    "Estimates probability, revenue impact, valuation impact per scenario",
                    "Assesses recovery likelihood and investment implications for each",
                ],
                "sources": ["Phase 1-2 reports", "Bear case", "Red flags", "Fact-check output"],
            },
            {
                "icon": "ğŸ“‹",
                "name": "Completeness Checker",
                "role": "QA audit â€” identifies coverage gaps and rates decision readiness.",
                "methodology": [
                    "Scores coverage across 7 dimensions (0-1): financial, market, legal, management, tech, valuation, risk",
                    "Identifies specific gaps that could affect the investment decision",
                    "Flags information quality issues (low confidence, unverified claims)",
                    "Recommends additional diligence items with priority ranking",
                    "Issues a verdict: READY / NEEDS MORE WORK / INSUFFICIENT",
                ],
                "sources": ["All prior Phase 1, 2, and Phase 3 outputs"],
            },
        ],
    },
    {
        "label": "Phase 4 â€” Investment Memo",
        "color": "#059669",
        "bg": "#f0fdf4",
        "description": "One final agent reads the **entire DD package** and writes a professional investment memo with a definitive INVEST / WATCH / PASS recommendation.",
        "agents": [
            {
                "icon": "ğŸ“",
                "name": "Final Report Agent",
                "role": "Synthesizes all 12 prior agents into a structured investment memo.",
                "methodology": [
                    "Reads all Phase 1-3 outputs holistically",
                    "Weighs bull case vs. bear case vs. verified facts vs. stress scenarios",
                    "Writes a full Markdown investment memo (Executive Summary â†’ Recommendation Rationale)",
                    "Issues **INVEST** (compelling upside, manageable risks), **WATCH** (interesting but uncertain), or **PASS** (risks outweigh opportunity)",
                    "Memo sections: Executive Summary, Thesis, Financials, Market, Management, Tech, Legal, Valuation, Stress Tests, Fact-Check, Recommendation",
                ],
                "sources": ["All 12 prior agent outputs (full DD package)"],
            },
        ],
    },
]


def _get_agent_phases(lang: str) -> list:
    """Return AGENT_PHASES with names/descriptions translated for the given language."""
    if lang == "en":
        return AGENT_PHASES

    # Korean overrides â€” methodology/sources stay in English (technical content)
    ko_meta = [
        {
            "label": "1ë‹¨ê³„ â€” ë³‘ë ¬ ë¦¬ì„œì¹˜",
            "description": "5ê°œì˜ ì „ë¬¸ ì—ì´ì „íŠ¸ê°€ **ë™ì‹œì—** ì‹¤í–‰ë©ë‹ˆë‹¤. ê°ê° ê¸°ì—…ì˜ ë‹¤ë¥¸ ì°¨ì›ì„ ë…ë¦½ì ìœ¼ë¡œ ë¦¬ì„œì¹˜í•˜ë©°, ì„œë¡œë¥¼ ê¸°ë‹¤ë¦¬ì§€ ì•ŠìŠµë‹ˆë‹¤.",
            "agents": [
                ("ğŸ’°", "ì¬ë¬´ ë¶„ì„ê°€",        "ì¬ë¬´ ê±´ì „ì„±, ìˆ˜ìµì„±, íšŒê³„ í’ˆì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤."),
                ("ğŸŒ", "ì‹œì¥ ë¦¬ì„œì²˜",        "TAM/SAM ì¶”ì •, ê²½ìŸ í™˜ê²½ ë¶„ì„, ê±°ì‹œ íŠ¸ë Œë“œ íŒŒì•…"),
                ("âš–ï¸", "ë²•ì  ë¦¬ìŠ¤í¬ ë¶„ì„ê°€",  "ì†Œì†¡, ê·œì œ ë…¸ì¶œ, IP ë¦¬ìŠ¤í¬, ê±°ë²„ë„ŒìŠ¤ ë¬¸ì œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."),
                ("ğŸ‘¥", "ê²½ì˜ì§„ ë¶„ì„ê°€",       "ì°½ì—…ì, ì„ì›ì§„, ì´ì‚¬íšŒ, ì¡°ì§ ì„±ìˆ™ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤."),
                ("ğŸ”¬", "ê¸°ìˆ Â·ì œí’ˆ ë¶„ì„ê°€",    "ì œí’ˆ ì„±ìˆ™ë„, ê¸°ìˆ  í•´ì, í™•ì¥ì„±, PMFë¥¼ í‰ê°€í•©ë‹ˆë‹¤."),
            ],
        },
        {
            "label": "2ë‹¨ê³„ â€” ë³‘ë ¬ ë¶„ì„",
            "description": "4ê°œì˜ íˆ¬ì ë…¼ê±° ì—ì´ì „íŠ¸ê°€ **ë™ì‹œì—** ì‹¤í–‰ë©ë‹ˆë‹¤. ê°ê° 1ë‹¨ê³„ ë³´ê³ ì„œë¥¼ ì „ë¶€ ì½ê³  ë‹¤ì–‘í•œ ê°ë„ì—ì„œ íˆ¬ì ê¸°íšŒë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.",
            "agents": [
                ("ğŸ“ˆ", "ê°•ì„¸ ë…¼ê±° ë¶„ì„ê°€",    "ê°€ì¥ ê°•ë ¥í•œ íˆ¬ì ë…¼ê±°ë¥¼ êµ¬ì¶•í•˜ê³  ìƒë°© ê°€ì¹˜ë¥¼ ìˆ˜ì¹˜í™”í•©ë‹ˆë‹¤."),
                ("ğŸ“‰", "ì•½ì„¸ ë…¼ê±° ë¶„ì„ê°€",    "íˆ¬ìì— ë°˜í•˜ëŠ” ê°€ì¥ ê°•ë ¥í•œ ì£¼ì¥ì„ êµ¬ì¶•í•˜ê³  ì¹˜ëª…ì  ê²°í•¨ì„ ì°¾ìŠµë‹ˆë‹¤."),
                ("ğŸ§®", "ë°¸ë¥˜ì—ì´ì…˜ ë¶„ì„ê°€",   "DCF, ë§¤ì¶œ ë°°ìˆ˜, ì„ ë¡€ ê±°ë˜ë¥¼ ì´ìš©í•´ ê³µì •ê°€ì¹˜ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤."),
                ("ğŸš©", "ìœ„í—˜ ì‹ í˜¸ íƒì§€ê¸°",    "1ë‹¨ê³„ ë³´ê³ ì„œ ì „ë°˜ì—ì„œ ëª¨ìˆœ, ëˆ„ë½, ì‚¬ê¸° ì‹ í˜¸ë¥¼ êµì°¨ ê²€í† í•©ë‹ˆë‹¤."),
            ],
        },
        {
            "label": "3ë‹¨ê³„ â€” ìˆœì°¨ ê²€ì¦",
            "description": "3ê°œì˜ QA ì—ì´ì „íŠ¸ê°€ **ìˆœì°¨ì ìœ¼ë¡œ** ì‹¤í–‰ë©ë‹ˆë‹¤. ê° ë‹¨ê³„ëŠ” ì´ì „ ë‹¨ê³„ ê²°ê³¼ì— ì˜ì¡´í•©ë‹ˆë‹¤. ìˆœì„œ: íŒ©íŠ¸ì²´í¬ â†’ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ â†’ ì™„ì„±ë„ ì ê²€.",
            "agents": [
                ("ğŸ”", "íŒ©íŠ¸ì²´ì»¤",            "1Â·2ë‹¨ê³„ì˜ ëª¨ë“  ì¤‘ìš” ì£¼ì¥ì„ ë…ë¦½ì ìœ¼ë¡œ ê²€ì¦í•©ë‹ˆë‹¤."),
                ("âš¡", "ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ë¶„ì„ê°€","í•˜ë°© ì‹œë‚˜ë¦¬ì˜¤ 3ê°€ì§€ë¥¼ ì •ëŸ‰ì  ì¬ë¬´ ì˜í–¥ê³¼ í•¨ê»˜ ëª¨ë¸ë§í•©ë‹ˆë‹¤."),
                ("ğŸ“‹", "ì™„ì„±ë„ ê²€ì‚¬ê¸°",        "QA ê°ì‚¬ â€” ì»¤ë²„ë¦¬ì§€ ê°­ì„ íŒŒì•…í•˜ê³  ì˜ì‚¬ê²°ì • ì¤€ë¹„ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤."),
            ],
        },
        {
            "label": "4ë‹¨ê³„ â€” íˆ¬ì ë©”ëª¨",
            "description": "ë§ˆì§€ë§‰ ì—ì´ì „íŠ¸ê°€ **ì „ì²´ DD íŒ¨í‚¤ì§€**ë¥¼ ì½ê³  INVEST / WATCH / PASS ê²°ì •ì„ ë‹´ì€ ì „ë¬¸ íˆ¬ì ë©”ëª¨ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.",
            "agents": [
                ("ğŸ“", "ìµœì¢… ë³´ê³ ì„œ ì—ì´ì „íŠ¸", "12ê°œ ì—ì´ì „íŠ¸ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ êµ¬ì¡°í™”ëœ íˆ¬ì ë©”ëª¨ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤."),
            ],
        },
    ]

    result = []
    for phase_en, phase_ko in zip(AGENT_PHASES, ko_meta):
        phase_new = dict(phase_en)
        phase_new["label"]       = phase_ko["label"]
        phase_new["description"] = phase_ko["description"]
        new_agents = []
        for agent_en, (icon_ko, name_ko, role_ko) in zip(phase_en["agents"], phase_ko["agents"]):
            agent_new          = dict(agent_en)
            agent_new["icon"]  = icon_ko
            agent_new["name"]  = name_ko
            agent_new["role"]  = role_ko
            new_agents.append(agent_new)
        phase_new["agents"] = new_agents
        result.append(phase_new)
    return result


# â”€â”€ Page config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="Due Diligence Agent",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="collapsed",
)

# â”€â”€ Custom CSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<style>
  .main .block-container { max-width: 1100px; padding-top: 1.5rem; }
  .invest-badge {
      background:#dcfce7; color:#15803d;
      padding:14px 40px; border-radius:14px;
      font-size:2.2rem; font-weight:900; letter-spacing:0.08em;
      display:inline-block; margin-bottom:6px;
  }
  .watch-badge {
      background:#fef3c7; color:#b45309;
      padding:14px 40px; border-radius:14px;
      font-size:2.2rem; font-weight:900; letter-spacing:0.08em;
      display:inline-block; margin-bottom:6px;
  }
  .pass-badge {
      background:#fee2e2; color:#b91c1c;
      padding:14px 40px; border-radius:14px;
      font-size:2.2rem; font-weight:900; letter-spacing:0.08em;
      display:inline-block; margin-bottom:6px;
  }
  .agent-card {
      background:#f8fafc; border:1px solid #e2e8f0;
      border-radius:10px; padding:14px 16px; margin-bottom:10px;
  }
  .source-tag {
      display:inline-block; background:#e0e7ff; color:#3730a3;
      border-radius:99px; padding:2px 10px; font-size:0.75rem;
      margin:2px 2px 2px 0;
  }
  .lang-toggle { font-size:0.8rem !important; padding:3px 10px !important; }
</style>
""", unsafe_allow_html=True)

# â”€â”€ Password gate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_app_password = ""
try:
    _app_password = str(st.secrets.get("APP_PASSWORD", ""))
except Exception:
    pass

if _app_password:
    if not st.session_state.get("authenticated"):
        _pw_hdr, _pw_lang = st.columns([5, 1])
        with _pw_hdr:
            st.markdown("## ğŸ“Š Due Diligence Agent")
        with _pw_lang:
            _cur_lang = st.session_state.get("ui_lang", "en")
            if st.button("í•œêµ­ì–´" if _cur_lang == "en" else "English", key="lang_btn_auth"):
                st.session_state.ui_lang = "ko" if _cur_lang == "en" else "en"
                st.rerun()
        st.divider()
        pwd = st.text_input(
            t("password_label"),
            type="password",
            placeholder=t("password_placeholder"),
        )
        if st.button(t("unlock_btn"), type="primary"):
            if pwd == _app_password:
                st.session_state.authenticated = True
                st.rerun()
            else:
                st.error(t("wrong_password"))
        st.stop()

# â”€â”€ API key check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_missing = validate_config()
if _missing:
    st.error(
        f"**Missing API keys:** {', '.join(_missing)}\n\n"
        "On **Streamlit Cloud**: go to your app â†’ âš™ï¸ Settings â†’ Secrets, and paste:\n"
        "```toml\n"
        'ANTHROPIC_API_KEY = "sk-ant-..."\n'
        'TAVILY_API_KEY = "tvly-..."\n'
        "```\n"
        "Running locally? Add those same lines to a `.env` file in the project folder."
    )
    st.stop()

# â”€â”€ Session state defaults â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for key, default in [
    ("phase", "form"),
    ("result", None),
    ("pdf_bytes", None),
    ("company", ""),
    ("job_id", None),
    ("history_pdf_cache", {}),
    ("ui_lang", "en"),
]:
    if key not in st.session_state:
        st.session_state[key] = default

# If there's an active job still running or queued, redirect to the running screen automatically
_active_job = st.session_state.get("job_id")
if _active_job and st.session_state.phase not in ("running", "results", "history"):
    if _read_job(_active_job).get("status") in ("running", "queued"):
        st.session_state.phase = "running"


# â”€â”€ Language toggle helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _lang_toggle(key_suffix: str = ""):
    """Render a compact language toggle button."""
    lang = st.session_state.get("ui_lang", "en")
    label = "í•œêµ­ì–´" if lang == "en" else "English"
    if st.button(label, key=f"lang_btn_{key_suffix}"):
        st.session_state.ui_lang = "ko" if lang == "en" else "en"
        st.rerun()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# HELPERS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def render_agent_card(agent: dict):
    with st.container():
        st.markdown(
            f"<div class='agent-card'>"
            f"<b>{agent['icon']} {agent['name']}</b><br>"
            f"<span style='color:#475569;font-size:0.88rem'>{agent['role']}</span>"
            f"</div>",
            unsafe_allow_html=True,
        )
        with st.expander(t("methodology_expander")):
            st.markdown(t("how_it_works"))
            for step in agent["methodology"]:
                st.markdown(f"- {step}")
            st.markdown(t("sources_label"))
            tags = "".join(
                f"<span class='source-tag'>{s}</span>" for s in agent["sources"]
            )
            st.markdown(tags, unsafe_allow_html=True)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SCREEN 1 â€” FORM
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.session_state.phase == "form":

    # â”€â”€ Header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    hdr_col, lang_col, hist_col = st.columns([5, 0.7, 0.8])
    with hdr_col:
        st.markdown(t("app_title"))
        st.caption(t("app_subtitle"))
    with lang_col:
        st.markdown("")
        _lang_toggle("form")
    with hist_col:
        st.markdown("")
        if st.button(t("history_btn"), use_container_width=True):
            st.session_state.phase = "history"
            st.rerun()
    st.divider()

    # â”€â”€ Two-column layout: form left, pipeline right â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    col_form, col_pipeline = st.columns([1, 1.4], gap="large")

    with col_form:
        st.markdown(t("form_heading"))
        company = st.text_input(
            t("company_label"),
            placeholder=t("company_placeholder"),
        )
        url = st.text_input(
            t("url_label"),
            placeholder=t("url_placeholder"),
        )
        language = st.radio(
            t("report_lang_label"),
            options=["English", "í•œêµ­ì–´"],
            horizontal=True,
            help="Choose the language for the entire analysis and investment memo.",
        )
        uploaded_files = st.file_uploader(
            t("docs_label"),
            type=["pdf"],
            accept_multiple_files=True,
            help=t("docs_help"),
        )
        st.markdown("")
        st.caption(t("cost_caption"))
        run = st.button(
            t("run_btn"),
            type="primary",
            disabled=not ((company or "").strip() and (url or "").strip()),
            use_container_width=True,
        )

    with col_pipeline:
        st.markdown(t("pipeline_heading"))
        st.caption(t("pipeline_caption"))
        st.graphviz_chart(PIPELINE_GRAPH, use_container_width=True)

    st.divider()

    # â”€â”€ Agent Directory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown(t("directory_heading"))
    st.caption(t("directory_caption"))
    st.markdown("")

    active_phases = _get_agent_phases(st.session_state.get("ui_lang", "en"))
    tabs = st.tabs([p["label"] for p in active_phases])
    for tab, phase in zip(tabs, active_phases):
        with tab:
            st.markdown(
                f"<p style='color:{phase['color']};font-size:0.9rem'>{phase['description']}</p>",
                unsafe_allow_html=True,
            )
            st.markdown("")
            n = len(phase["agents"])
            cols = st.columns(min(n, 2))
            for i, agent in enumerate(phase["agents"]):
                with cols[i % 2]:
                    render_agent_card(agent)

    # â”€â”€ Analysis runner â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if run and company.strip() and url.strip():
        tmp_dir = tempfile.mkdtemp()
        doc_paths: list[str] = []
        for f in (uploaded_files or []):
            dest = os.path.join(tmp_dir, f.name)
            with open(dest, "wb") as out:
                out.write(f.getbuffer())
            doc_paths.append(dest)

        job_id = str(uuid.uuid4())
        # Map display label to canonical language string
        lang_map = {"English": "English", "í•œêµ­ì–´": "Korean"}
        lang_value = lang_map.get(language, "English")

        initial_state = {
            "company_name": company.strip(),
            "company_url": url.strip(),
            "uploaded_docs": doc_paths,
            "language": lang_value,
            "financial_report": None,
            "market_report": None,
            "legal_report": None,
            "management_report": None,
            "tech_report": None,
            "bull_case": None,
            "bear_case": None,
            "valuation": None,
            "red_flags": [],
            "verification": None,
            "stress_test": None,
            "completeness": None,
            "final_report": None,
            "recommendation": None,
            "messages": [],
            "errors": [],
            "current_phase": "init",
        }

        _update_job(job_id, {
            "status": "running",
            "progress": [],
            "error": None,
            "start_time": time.time(),
        })

        t_thread = threading.Thread(
            target=_analysis_worker,
            args=(job_id, initial_state, company.strip(), tmp_dir),
            daemon=True,
        )
        t_thread.start()

        st.session_state.job_id = job_id
        st.session_state.company = company.strip()
        st.session_state.phase = "running"
        st.rerun()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SCREEN 2 â€” RUNNING (background thread progress)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif st.session_state.phase == "running":
    job_id  = st.session_state.get("job_id", "")
    company = st.session_state.get("company", "")

    job = _read_job(job_id)

    if job["status"] == "complete":
        pdf_path = job.get("pdf_path", "")
        pdf_bytes = Path(pdf_path).read_bytes() if pdf_path and Path(pdf_path).exists() else b""
        st.session_state.result = {
            "final_report":   job.get("final_report", ""),
            "recommendation": job.get("recommendation", "WATCH"),
            "token_usage":    job.get("token_usage", {}),
        }
        st.session_state.pdf_bytes = pdf_bytes
        st.session_state.history_pdf_cache[job_id] = pdf_bytes
        st.session_state.phase = "results"
        st.rerun()

    elif job["status"] == "error":
        st.error(t("analysis_failed", job.get("error", "Unknown error")))
        st.session_state.job_id = None
        if st.button(t("try_again_btn")):
            st.session_state.phase = "form"
            st.rerun()

    elif job["status"] == "queued":
        # Waiting for a semaphore slot â€” show queue message
        _q_hdr, _q_lang = st.columns([5, 1])
        with _q_hdr:
            st.markdown(t("queued_heading", company))
            st.caption(t("queued_caption"))
        with _q_lang:
            _lang_toggle("queued")
        st.info(t("queued_info"))
        elapsed_sec = time.time() - (job.get("start_time") or time.time())
        st.caption(t("waiting_caption", int(elapsed_sec)))
        time.sleep(5)
        st.rerun()

    else:
        # Still running â€” show live progress and poll
        _node_labels = _NODE_LABELS_KO if st.session_state.get("ui_lang") == "ko" else _NODE_LABELS_EN

        _run_hdr, _run_lang, _run_hist = st.columns([5, 0.7, 0.8])
        with _run_hdr:
            st.markdown(t("analyzing", company))
            st.caption(t("running_caption"))
        with _run_lang:
            _lang_toggle("running")
        with _run_hist:
            st.markdown("")
            if st.button(t("history_btn"), use_container_width=True, key="hist_running"):
                st.session_state.phase = "history"
                st.rerun()

        st.divider()

        progress    = job.get("progress") or []
        start_time  = job.get("start_time") or time.time()
        elapsed_sec = time.time() - start_time

        # â”€â”€ Progress calculation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        completed_weight = sum(NODE_WEIGHTS.get(n, 0) for n in progress)
        total_weight     = sum(NODE_WEIGHTS.values())
        pct = completed_weight / total_weight  # 0.0 â†’ 1.0

        # Elapsed + estimated remaining
        def _fmt_time(seconds: float) -> str:
            seconds = int(seconds)
            if seconds < 60:
                return f"{seconds}s"
            return f"{seconds // 60}m {seconds % 60:02d}s"

        elapsed_str = _fmt_time(elapsed_sec)
        if pct > 0.02:
            est_total  = elapsed_sec / pct
            remaining  = max(0, est_total - elapsed_sec)
            eta_str    = t("eta_remaining", _fmt_time(remaining))
        else:
            eta_str = t("eta_estimating")

        # â”€â”€ Progress bar + stats row â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        steps_done  = len(progress)
        steps_total = len(_node_labels)
        st.progress(pct, text=t(
            "progress_text",
            pct=int(pct * 100),
            done=steps_done,
            total=steps_total,
            elapsed=elapsed_str,
            eta=eta_str,
        ))

        # â”€â”€ Live cost tracker â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        token_usage = job.get("token_usage") or {}
        total_cost  = sum(v.get("cost_usd", 0)       for v in token_usage.values())
        total_in    = sum(v.get("input_tokens", 0)    for v in token_usage.values())
        total_out   = sum(v.get("output_tokens", 0)   for v in token_usage.values())
        if token_usage:
            st.caption(t("api_cost", cost=total_cost, inp=total_in, out=total_out))

        st.markdown("")

        # â”€â”€ Completed steps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        for node in progress:
            label = _node_labels.get(node, node.replace("_", " ").title())
            # Show per-node cost for steps that use the LLM
            if node in ("phase1_parallel", "phase2_parallel"):
                phase_agents = (
                    ["financial_analyst","market_research","legal_risk","management_team","tech_product"]
                    if node == "phase1_parallel" else
                    ["bull_case","bear_case","valuation","red_flag"]
                )
                phase_cost = sum(token_usage.get(a, {}).get("cost_usd", 0) for a in phase_agents)
                st.write(f"âœ“ {label}  â€”  ${phase_cost:.4f}")
            elif node not in ("input_processor", "phase1_aggregator", "phase2_aggregator"):
                node_cost = token_usage.get(node, {}).get("cost_usd", 0)
                if node_cost:
                    st.write(f"âœ“ {_node_labels.get(node, node)}  â€”  ${node_cost:.4f}")
                else:
                    st.write(f"âœ“ {_node_labels.get(node, node)}")
            else:
                st.write(f"âœ“ {label}")

        # â”€â”€ Current step spinner â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        completed_set = set(progress)
        for node in _node_labels:
            if node not in completed_set:
                st.write(f"â³ {_node_labels[node]}â€¦")
                break

        # Poll every 3 seconds
        time.sleep(3)
        st.rerun()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SCREEN 3 â€” RESULTS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif st.session_state.phase == "results":
    result:  dict = st.session_state.result or {}
    company: str  = st.session_state.company
    rec = (result.get("recommendation") or "WATCH").upper()

    badge_class = {
        "INVEST": "invest-badge",
        "WATCH":  "watch-badge",
        "PASS":   "pass-badge",
    }.get(rec, "watch-badge")

    rec_desc = {
        "INVEST": t("invest_desc"),
        "WATCH":  t("watch_desc"),
        "PASS":   t("pass_desc"),
    }.get(rec, "")

    _res_hdr, _res_lang = st.columns([5, 1])
    with _res_hdr:
        st.markdown(f"### {company}")
        st.markdown(f'<div class="{badge_class}">{rec}</div>', unsafe_allow_html=True)
        st.caption(rec_desc)
    with _res_lang:
        st.markdown("")
        _lang_toggle("results")
    st.divider()

    col_dl, col_reset, col_hist, _ = st.columns([1, 1, 1, 1])
    with col_dl:
        if st.session_state.pdf_bytes:
            st.download_button(
                label=t("download_btn"),
                data=st.session_state.pdf_bytes,
                file_name=f"due_diligence_{company.replace(' ', '_')}.pdf",
                mime="application/pdf",
                type="primary",
                use_container_width=True,
            )
    with col_reset:
        if st.button(t("analyze_another_btn"), use_container_width=True):
            st.session_state.phase    = "form"
            st.session_state.result   = None
            st.session_state.pdf_bytes = None
            st.session_state.job_id   = None
            st.rerun()
    with col_hist:
        if st.button(t("history_btn"), use_container_width=True, key="hist_results"):
            st.session_state.phase = "history"
            st.rerun()

    st.divider()

    # â”€â”€ Token usage & cost breakdown â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    token_usage: dict = result.get("token_usage") or {}
    if token_usage:
        total_in   = sum(v.get("input_tokens",  0) for v in token_usage.values())
        total_out  = sum(v.get("output_tokens", 0) for v in token_usage.values())
        total_cost = sum(v.get("cost_usd",      0) for v in token_usage.values())

        with st.expander(t("token_expander", total_cost), expanded=False):
            st.caption(t("token_caption"))
            st.markdown("")

            # Agent labels in the active language
            _agent_labels = _AGENT_LABELS_KO if st.session_state.get("ui_lang") == "ko" else _AGENT_LABELS_EN

            # Table rows in display order
            rows = []
            for key in _AGENT_ORDER:
                if key not in token_usage:
                    continue
                v = token_usage[key]
                rows.append({
                    t("agent_col"):         _agent_labels.get(key, key),
                    t("input_tokens_col"):  f"{v.get('input_tokens',  0):,}",
                    t("output_tokens_col"): f"{v.get('output_tokens', 0):,}",
                    t("cost_col"):          f"${v.get('cost_usd', 0):.4f}",
                })

            # Summary row
            rows.append({
                t("agent_col"):         t("total_label"),
                t("input_tokens_col"):  f"**{total_in:,}**",
                t("output_tokens_col"): f"**{total_out:,}**",
                t("cost_col"):          f"**${total_cost:.4f}**",
            })

            st.table(rows)

    st.divider()

    final_report: str = result.get("final_report") or ""
    if final_report.strip():
        st.markdown(final_report)
    else:
        st.info(t("no_report"))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SCREEN 4 â€” HISTORY
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
elif st.session_state.phase == "history":
    _hist_hdr, _hist_lang = st.columns([5, 1])
    with _hist_hdr:
        st.markdown(t("history_title"))
        st.caption(t("history_caption"))
    with _hist_lang:
        _lang_toggle("history")

    _back_job   = st.session_state.get("job_id")
    _back_label = t("back_btn")
    _back_phase = "form"
    if _back_job and _read_job(_back_job).get("status") in ("running", "queued"):
        _back_label = t("back_running_btn")
        _back_phase = "running"
    if st.button(_back_label):
        st.session_state.phase = _back_phase
        st.rerun()
    st.divider()

    history = _load_history()

    if not history:
        st.info(t("no_history"))
    else:
        badge_css = {
            "INVEST": ("background:#dcfce7;color:#15803d", "INVEST"),
            "WATCH":  ("background:#fef3c7;color:#b45309", "WATCH"),
            "PASS":   ("background:#fee2e2;color:#b91c1c", "PASS"),
        }
        for entry in history:
            rec    = (entry.get("recommendation") or "WATCH").upper()
            style, label = badge_css.get(rec, badge_css["WATCH"])
            badge_html = (
                f"<span style='{style};padding:3px 12px;border-radius:8px;"
                f"font-weight:700;font-size:0.85rem'>{label}</span>"
            )
            col_name, col_rec, col_date, col_dl = st.columns([2.5, 1, 1.5, 1])
            with col_name:
                st.markdown(f"**{entry.get('company', 'â€”')}**")
            with col_rec:
                st.markdown(badge_html, unsafe_allow_html=True)
            with col_date:
                st.caption(entry.get("date", ""))
            with col_dl:
                job_id   = entry.get("id", "")
                pdf_bytes = st.session_state.history_pdf_cache.get(job_id)
                if pdf_bytes is None:
                    pdf_path = entry.get("pdf_path", "")
                    if pdf_path and Path(pdf_path).exists():
                        try:
                            pdf_bytes = Path(pdf_path).read_bytes()
                            st.session_state.history_pdf_cache[job_id] = pdf_bytes
                        except Exception:
                            pdf_bytes = None
                if pdf_bytes:
                    fname = f"dd_{entry.get('company','report').replace(' ','_')}.pdf"
                    st.download_button(
                        label=t("pdf_btn"),
                        data=pdf_bytes,
                        file_name=fname,
                        mime="application/pdf",
                        key=f"dl_{job_id}",
                        use_container_width=True,
                    )
                else:
                    st.caption(t("pdf_unavail"))
            st.divider()
